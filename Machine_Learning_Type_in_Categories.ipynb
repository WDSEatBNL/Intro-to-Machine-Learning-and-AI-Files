{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOQRiop9VImaBMRNmpHrmwE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WDSEatBNL/Intro-to-Machine-Learning-and-AI-Files/blob/master/Machine_Learning_Type_in_Categories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the libraries that we need to train and test a neural network"
      ],
      "metadata": {
        "id": "UFdwy4z5UNg3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5Qr05XAR131"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from skimage import io\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Image, clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load in our image files from github"
      ],
      "metadata": {
        "id": "fRg4W96SzSrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WDSEatBNL/Intro-to-Machine-Learning-and-AI-Files"
      ],
      "metadata": {
        "id": "XSpVjIgUzXNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the files from the \"images\" folder (found in \"content/Intro-to-Machine-Learning-and-AI-Files) and ask the user to name the images based on the categories from their card game\n",
        "\n",
        "***Instructions:*** After running the cell below, you will see an image, an input box, and a submit button. Enter your label in the input box and click 'Submit Label' to proceed to the next image."
      ],
      "metadata": {
        "id": "V-Jqc4XPUEK2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f24b2c51"
      },
      "source": [
        "IMG_HEIGHT = 288\n",
        "IMG_WIDTH = 288\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_data_dir = r'/content/Intro-to-Machine-Learning-and-AI-Files/images'\n",
        "image_files = [f for f in os.listdir(train_data_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "\n",
        "collected_image_labels = {}\n",
        "current_image_index = 0\n",
        "\n",
        "image_widget = widgets.Image(width=300)\n",
        "label_input = widgets.Text(description='Label:')\n",
        "submit_button = widgets.Button(description='Submit Label')\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def display_next_image():\n",
        "    global current_image_index\n",
        "    if current_image_index < len(image_files):\n",
        "        current_image_file = image_files[current_image_index]\n",
        "        filepath = os.path.join(train_data_dir, current_image_file)\n",
        "\n",
        "        with open(filepath, 'rb') as f:\n",
        "            image_data = f.read()\n",
        "        image_widget.value = image_data\n",
        "        label_input.value = '' # Clear previous input\n",
        "        label_input.placeholder = f\"Enter label for {current_image_file}\"\n",
        "        with output_area:\n",
        "            clear_output(wait=True)\n",
        "            print(f\"Labeling image {current_image_index + 1}/{len(image_files)}: {current_image_file}\")\n",
        "    else:\n",
        "        with output_area:\n",
        "            clear_output(wait=True)\n",
        "            print(\"Labeling complete!\")\n",
        "            print(\"Collected labels:\")\n",
        "            for filename, label in collected_image_labels.items():\n",
        "                print(f\"  {filename}: {label}\")\n",
        "        submit_button.disabled = True\n",
        "        label_input.disabled = True\n",
        "\n",
        "def on_submit_button_clicked(b):\n",
        "    global current_image_index\n",
        "    current_image_file = image_files[current_image_index]\n",
        "    label = label_input.value.strip()\n",
        "    if label:\n",
        "        collected_image_labels[current_image_file] = label\n",
        "        current_image_index += 1\n",
        "        display_next_image()\n",
        "    else:\n",
        "        with output_area:\n",
        "            print(\"Please enter a label before submitting.\")\n",
        "\n",
        "submit_button.on_click(on_submit_button_clicked)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    image_widget,\n",
        "    widgets.HBox([label_input, submit_button]),\n",
        "    output_area\n",
        "]))\n",
        "display_next_image()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translate the category names into integers for tensorflow to read"
      ],
      "metadata": {
        "id": "hWIFNVYJ5t51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_string_labels = list(collected_image_labels.values())\n",
        "class_names = sorted(list(set(all_string_labels)))\n",
        "\n",
        "label_to_index = {label: i for i, label in enumerate(class_names)}\n",
        "\n",
        "sorted_image_filenames = sorted(image_files)\n",
        "ordered_integer_labels = [label_to_index[collected_image_labels[filename]] for filename in sorted_image_filenames]\n",
        "\n",
        "print(f\"Unique class names (sorted): {class_names}\")\n",
        "print(f\"Number of classes: {len(class_names)}\")"
      ],
      "metadata": {
        "id": "Hq1rx0tZ5waA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into a training set and a validation set (set aside 20% of the images for testing), then apply integer labels to each image"
      ],
      "metadata": {
        "id": "9xh6R3C7UgS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_split_percentage = 0.2\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_data_dir,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    labels=ordered_integer_labels,\n",
        "    validation_split=validation_split_percentage,\n",
        "    subset='training',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_data_dir,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    labels=ordered_integer_labels,\n",
        "    validation_split=validation_split_percentage,\n",
        "    subset='validation',\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "id": "Jh80IbICUkff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up the model for training (normalize images, adjust settings for the model, and compile the model)"
      ],
      "metadata": {
        "id": "PoytBA-w9jd0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-3IzFU19u"
      },
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "norm_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "norm_val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "num_classes = len(class_names)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu',\n",
        "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model and assign a category name to each image in the validation set (epochs tells you the number of times the model will train and check accuracy before training is complete)"
      ],
      "metadata": {
        "id": "GGOFklgm_x6C"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d481d4d8"
      },
      "source": [
        "epochs = 10\n",
        "history = model.fit(norm_train_ds, validation_data=norm_val_ds, epochs=epochs)\n",
        "\n",
        "prediction = model.predict(norm_val_ds)\n",
        "\n",
        "predicted_classes = np.argmax(prediction, axis=1)\n",
        "predicted_class_names = [class_names[i] for i in predicted_classes]\n",
        "\n",
        "actual_classes = []\n",
        "for images, labels in norm_val_ds:\n",
        "    actual_classes.append(labels.numpy())\n",
        "concatenated_labels = np.concatenate(actual_classes, axis=0)\n",
        "actual_class_names = [class_names[i] for i in concatenated_labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show each validation image with its predicted category"
      ],
      "metadata": {
        "id": "t0Fzd2X8VQnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10, 10))\n",
        "for images, labels in val_ds.take(1):\n",
        "    for i in range(len(predicted_class_names)):\n",
        "        ax = plt.subplot(4, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(predicted_class_names[i])\n",
        "        plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mZgtFcVyVUks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the accuracy of the model in the form of percent correctly identified"
      ],
      "metadata": {
        "id": "NOzMD6n9VXBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Percentage correct: ', 100*np.sum(concatenated_labels == predicted_classes)/len(predicted_classes))"
      ],
      "metadata": {
        "id": "4GhGg3iYVZdt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}